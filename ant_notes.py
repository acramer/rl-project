A. Environment
A.I Static
    1. Create a 2D matrix
    2. Randomly put food
    3. Create obstacles
    4. Initialize location of nest
    # 5. Store optimal paths in a dictionary
A.II Dynamic
    5. Setting pheromone trail generated by the ant

B. Agents
    0. If ant has food in pincers, worker_flag: True, else: False
    1. Exploring ant -> reward based on exploring new locations and food. Cost walking < exploiting ant
        1.a. With food in pincers worker_flag true: cost walking ++ 
    2. Exploiting ant -> reward get food from location with highest efficiency. Cost walking > exploring ant.
        2.a. Following pheromone trail less costly.
        2.b. With food in pincers worker_flag true: cost walking ++ 

C. Rewards
    1. Exploration
        a. New tile explored: +1
        b. New food found: +10
        c. Dropping food at nest: +75
        d. Walking cost when worker_flag==True: -1
        e. Walking on already explored tile: +0
    2. Exploitation
        a. New tile explored: +0
        b. New food found: +5
        c. Dropping food at nest: +50
        d. Walking cost when worker_flag==False: 0, if on trail: +1
        e. Walking cost when worker_flag==True: -2, if on trail: +1
